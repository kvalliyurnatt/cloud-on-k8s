# RAG Implementation Plan: Ollama (Fully Local)

> **Status**: Planned (not yet implemented)
> **Approach**: 100% local RAG using Ollama for embeddings and LLM
> **Estimated Effort**: 2-3 days
> **Cost**: $0 (completely free)
> **Prerequisites**: Ollama installed, ~3GB disk space for models

## Overview

A fully local RAG solution using Ollama for both embedding generation and LLM inference. This approach provides:
- **Zero cost** - no API fees
- **No rate limits** - run as much as you want
- **Complete privacy** - code never leaves your machine
- **Offline capable** - works without internet after initial model download

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Ollama RAG Architecture                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                 One-Time Indexing (build-index command)               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ  ECK Source  ‚îÇ‚îÄ‚îÄ‚îÄ>‚îÇ    Chunker      ‚îÇ‚îÄ‚îÄ‚îÄ>‚îÇ  Ollama Embeddings ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ  (.go files) ‚îÇ    ‚îÇ (AST-aware for  ‚îÇ    ‚îÇ (nomic-embed-text) ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ              ‚îÇ    ‚îÇ  Go functions)  ‚îÇ    ‚îÇ                    ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚ñº              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                              ‚îÇ  Vector Store      ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                              ‚îÇ  (vectors.gob)     ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                              ‚îÇ  - Embeddings      ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                              ‚îÇ  - Metadata        ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                              ‚îÇ  - Code chunks     ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                    Runtime (Per CVE Triage)                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ  CVE Query   ‚îÇ‚îÄ‚îÄ‚îÄ>‚îÇ Ollama Embeddings‚îÇ‚îÄ‚îÄ‚îÄ>‚îÇ  Similarity Search ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ + Affected   ‚îÇ    ‚îÇ (same model)    ‚îÇ    ‚îÇ  (cosine distance) ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ   packages   ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                    ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚ñº              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ  Top-K Code  ‚îÇ‚îÄ‚îÄ‚îÄ>‚îÇ   Build Prompt  ‚îÇ‚îÄ‚îÄ‚îÄ>‚îÇ    Ollama LLM      ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ   Chunks     ‚îÇ    ‚îÇ  with Context   ‚îÇ    ‚îÇ   (llama3.2 or     ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ              ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ    mistral)        ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚ñº              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                              ‚îÇ  Grounded Analysis ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                              ‚îÇ  with Code Refs    ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  Benefits: ‚úÖ Free  ‚úÖ No rate limits  ‚úÖ Private  ‚úÖ Offline capable      ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Setup

### Install Ollama

```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.com/install.sh | sh

# Start service
ollama serve
```

### Pull Required Models

```bash
# Embedding model (required) - 274MB
ollama pull nomic-embed-text

# LLM model (choose one)
ollama pull llama3.2      # 2GB, fast, good quality
ollama pull mistral       # 4GB, better reasoning
ollama pull codellama     # 4GB, code-focused
```

## Implementation

### File Structure

```
hack/cve-triage/
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ provider.go      # Provider interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ollama.go        # Existing Ollama LLM
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analyzer.go      # Gemini implementation
‚îÇ   ‚îî‚îÄ‚îÄ rag/
‚îÇ       ‚îú‚îÄ‚îÄ embeddings.go    # Ollama embedding client
‚îÇ       ‚îú‚îÄ‚îÄ chunker.go       # Code chunking (AST-aware)
‚îÇ       ‚îú‚îÄ‚îÄ vectorstore.go   # Local vector store
‚îÇ       ‚îú‚îÄ‚îÄ retriever.go     # Similarity search
‚îÇ       ‚îî‚îÄ‚îÄ rag.go           # RAG orchestrator
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îî‚îÄ‚îÄ index/
‚îÇ       ‚îî‚îÄ‚îÄ main.go          # Index building command
‚îî‚îÄ‚îÄ data/
    ‚îî‚îÄ‚îÄ vectors.gob          # Persisted vector store
```

### 1. Ollama Embeddings Client (`internal/rag/embeddings.go`)

```go
// Copyright Elasticsearch B.V.

package rag

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"time"
)

const (
	DefaultOllamaURL         = "http://localhost:11434"
	DefaultEmbeddingModel    = "nomic-embed-text"
	EmbeddingDimension       = 768  // nomic-embed-text dimension
)

// OllamaEmbedder generates embeddings using Ollama
type OllamaEmbedder struct {
	baseURL string
	model   string
	client  *http.Client
}

// EmbeddingRequest is the Ollama embedding API request
type EmbeddingRequest struct {
	Model  string `json:"model"`
	Prompt string `json:"prompt"`
}

// EmbeddingResponse is the Ollama embedding API response
type EmbeddingResponse struct {
	Embedding []float32 `json:"embedding"`
}

// NewOllamaEmbedder creates a new embedder
func NewOllamaEmbedder(baseURL, model string) *OllamaEmbedder {
	if baseURL == "" {
		baseURL = DefaultOllamaURL
	}
	if model == "" {
		model = DefaultEmbeddingModel
	}
	return &OllamaEmbedder{
		baseURL: baseURL,
		model:   model,
		client: &http.Client{
			Timeout: 30 * time.Second,
		},
	}
}

// Embed generates an embedding for the given text
func (e *OllamaEmbedder) Embed(ctx context.Context, text string) ([]float32, error) {
	reqBody := EmbeddingRequest{
		Model:  e.model,
		Prompt: text,
	}

	jsonBody, err := json.Marshal(reqBody)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal request: %w", err)
	}

	req, err := http.NewRequestWithContext(ctx, "POST", e.baseURL+"/api/embeddings", bytes.NewReader(jsonBody))
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %w", err)
	}
	req.Header.Set("Content-Type", "application/json")

	resp, err := e.client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("failed to call Ollama: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return nil, fmt.Errorf("Ollama returned status %d: %s", resp.StatusCode, string(body))
	}

	var embResp EmbeddingResponse
	if err := json.NewDecoder(resp.Body).Decode(&embResp); err != nil {
		return nil, fmt.Errorf("failed to decode response: %w", err)
	}

	return embResp.Embedding, nil
}

// EmbedBatch generates embeddings for multiple texts
func (e *OllamaEmbedder) EmbedBatch(ctx context.Context, texts []string) ([][]float32, error) {
	embeddings := make([][]float32, len(texts))
	for i, text := range texts {
		emb, err := e.Embed(ctx, text)
		if err != nil {
			return nil, fmt.Errorf("failed to embed text %d: %w", i, err)
		}
		embeddings[i] = emb
	}
	return embeddings, nil
}

// IsAvailable checks if Ollama embedding service is available
func (e *OllamaEmbedder) IsAvailable(ctx context.Context) bool {
	// Try to generate a simple embedding
	_, err := e.Embed(ctx, "test")
	return err == nil
}

// ModelInfo returns info about the embedding model
func (e *OllamaEmbedder) ModelInfo() (model string, dimension int) {
	return e.model, EmbeddingDimension
}
```

### 2. AST-Aware Code Chunker (`internal/rag/chunker.go`)

```go
// Copyright Elasticsearch B.V.

package rag

import (
	"go/ast"
	"go/parser"
	"go/token"
	"io/fs"
	"os"
	"path/filepath"
	"strings"
)

// CodeChunk represents a chunk of code for embedding
type CodeChunk struct {
	ID       string   `json:"id"`
	FilePath string   `json:"filePath"`
	StartLine int     `json:"startLine"`
	EndLine   int     `json:"endLine"`
	Type     string   `json:"type"`     // "function", "method", "type", "const", "var"
	Name     string   `json:"name"`     // Function/type name
	Package  string   `json:"package"`  // Package name
	Content  string   `json:"content"`  // Actual code
	Imports  []string `json:"imports"`  // Relevant imports
}

// Chunker splits Go source files into semantic chunks
type Chunker struct {
	maxChunkSize int
	repoPath     string
}

// NewChunker creates a new code chunker
func NewChunker(repoPath string, maxChunkSize int) *Chunker {
	if maxChunkSize == 0 {
		maxChunkSize = 2000 // ~500 tokens
	}
	return &Chunker{
		maxChunkSize: maxChunkSize,
		repoPath:     repoPath,
	}
}

// ChunkRepository processes all Go files in the repository
func (c *Chunker) ChunkRepository() ([]CodeChunk, error) {
	var chunks []CodeChunk

	err := filepath.WalkDir(c.repoPath, func(path string, d fs.DirEntry, err error) error {
		if err != nil {
			return err
		}

		// Skip directories
		if d.IsDir() {
			// Skip vendor, test, and generated directories
			name := d.Name()
			if name == "vendor" || name == ".git" || name == "hack" {
				return filepath.SkipDir
			}
			return nil
		}

		// Only process .go files, skip tests
		if !strings.HasSuffix(path, ".go") || strings.HasSuffix(path, "_test.go") {
			return nil
		}

		// Skip generated files
		if strings.Contains(path, "zz_generated") {
			return nil
		}

		fileChunks, err := c.chunkFile(path)
		if err != nil {
			// Log error but continue with other files
			return nil
		}

		chunks = append(chunks, fileChunks...)
		return nil
	})

	return chunks, err
}

// chunkFile processes a single Go file into chunks
func (c *Chunker) chunkFile(filePath string) ([]CodeChunk, error) {
	fset := token.NewFileSet()
	node, err := parser.ParseFile(fset, filePath, nil, parser.ParseComments)
	if err != nil {
		return nil, err
	}

	content, err := os.ReadFile(filePath)
	if err != nil {
		return nil, err
	}

	var chunks []CodeChunk
	relPath, _ := filepath.Rel(c.repoPath, filePath)

	// Extract imports
	var imports []string
	for _, imp := range node.Imports {
		imports = append(imports, strings.Trim(imp.Path.Value, `"`))
	}

	// Process declarations
	for _, decl := range node.Decls {
		switch d := decl.(type) {
		case *ast.FuncDecl:
			chunk := c.extractFuncChunk(fset, d, relPath, node.Name.Name, imports, content)
			if chunk != nil {
				chunks = append(chunks, *chunk)
			}
		case *ast.GenDecl:
			chunkList := c.extractGenDeclChunks(fset, d, relPath, node.Name.Name, imports, content)
			chunks = append(chunks, chunkList...)
		}
	}

	return chunks, nil
}

// extractFuncChunk extracts a function/method as a chunk
func (c *Chunker) extractFuncChunk(fset *token.FileSet, fn *ast.FuncDecl, filePath, pkgName string, imports []string, content []byte) *CodeChunk {
	startPos := fset.Position(fn.Pos())
	endPos := fset.Position(fn.End())

	code := string(content[fn.Pos()-1 : fn.End()-1])
	if len(code) > c.maxChunkSize {
		// Truncate but keep signature
		code = code[:c.maxChunkSize] + "\n// ... truncated"
	}

	chunkType := "function"
	name := fn.Name.Name
	if fn.Recv != nil {
		chunkType = "method"
		// Get receiver type
		if len(fn.Recv.List) > 0 {
			if star, ok := fn.Recv.List[0].Type.(*ast.StarExpr); ok {
				if ident, ok := star.X.(*ast.Ident); ok {
					name = ident.Name + "." + name
				}
			} else if ident, ok := fn.Recv.List[0].Type.(*ast.Ident); ok {
				name = ident.Name + "." + name
			}
		}
	}

	return &CodeChunk{
		ID:        filePath + ":" + name,
		FilePath:  filePath,
		StartLine: startPos.Line,
		EndLine:   endPos.Line,
		Type:      chunkType,
		Name:      name,
		Package:   pkgName,
		Content:   code,
		Imports:   imports,
	}
}

// extractGenDeclChunks extracts type/const/var declarations
func (c *Chunker) extractGenDeclChunks(fset *token.FileSet, gen *ast.GenDecl, filePath, pkgName string, imports []string, content []byte) []CodeChunk {
	var chunks []CodeChunk

	for _, spec := range gen.Specs {
		switch s := spec.(type) {
		case *ast.TypeSpec:
			startPos := fset.Position(s.Pos())
			endPos := fset.Position(s.End())
			code := string(content[s.Pos()-1 : s.End()-1])

			chunks = append(chunks, CodeChunk{
				ID:        filePath + ":" + s.Name.Name,
				FilePath:  filePath,
				StartLine: startPos.Line,
				EndLine:   endPos.Line,
				Type:      "type",
				Name:      s.Name.Name,
				Package:   pkgName,
				Content:   code,
				Imports:   imports,
			})
		}
	}

	return chunks
}
```

### 3. Local Vector Store (`internal/rag/vectorstore.go`)

```go
// Copyright Elasticsearch B.V.

package rag

import (
	"encoding/gob"
	"fmt"
	"math"
	"os"
	"sort"
	"sync"
)

// VectorEntry stores a chunk with its embedding
type VectorEntry struct {
	Chunk     CodeChunk
	Embedding []float32
}

// VectorStore is an in-memory vector store with file persistence
type VectorStore struct {
	entries []VectorEntry
	mu      sync.RWMutex
}

// SearchResult represents a similarity search result
type SearchResult struct {
	Chunk    CodeChunk
	Score    float32 // Cosine similarity (higher = more similar)
	Distance float32 // Cosine distance (lower = more similar)
}

// NewVectorStore creates a new vector store
func NewVectorStore() *VectorStore {
	return &VectorStore{
		entries: make([]VectorEntry, 0),
	}
}

// Add adds a chunk with its embedding to the store
func (vs *VectorStore) Add(chunk CodeChunk, embedding []float32) {
	vs.mu.Lock()
	defer vs.mu.Unlock()
	vs.entries = append(vs.entries, VectorEntry{
		Chunk:     chunk,
		Embedding: embedding,
	})
}

// AddBatch adds multiple chunks with their embeddings
func (vs *VectorStore) AddBatch(chunks []CodeChunk, embeddings [][]float32) error {
	if len(chunks) != len(embeddings) {
		return fmt.Errorf("chunks and embeddings length mismatch")
	}
	vs.mu.Lock()
	defer vs.mu.Unlock()
	for i := range chunks {
		vs.entries = append(vs.entries, VectorEntry{
			Chunk:     chunks[i],
			Embedding: embeddings[i],
		})
	}
	return nil
}

// Search finds the top-k most similar chunks to the query embedding
func (vs *VectorStore) Search(queryEmbedding []float32, topK int) []SearchResult {
	vs.mu.RLock()
	defer vs.mu.RUnlock()

	results := make([]SearchResult, len(vs.entries))
	for i, entry := range vs.entries {
		score := cosineSimilarity(queryEmbedding, entry.Embedding)
		results[i] = SearchResult{
			Chunk:    entry.Chunk,
			Score:    score,
			Distance: 1 - score,
		}
	}

	// Sort by score descending
	sort.Slice(results, func(i, j int) bool {
		return results[i].Score > results[j].Score
	})

	if topK > len(results) {
		topK = len(results)
	}

	return results[:topK]
}

// Size returns the number of entries in the store
func (vs *VectorStore) Size() int {
	vs.mu.RLock()
	defer vs.mu.RUnlock()
	return len(vs.entries)
}

// Save persists the vector store to disk
func (vs *VectorStore) Save(path string) error {
	vs.mu.RLock()
	defer vs.mu.RUnlock()

	file, err := os.Create(path)
	if err != nil {
		return fmt.Errorf("failed to create file: %w", err)
	}
	defer file.Close()

	encoder := gob.NewEncoder(file)
	if err := encoder.Encode(vs.entries); err != nil {
		return fmt.Errorf("failed to encode: %w", err)
	}

	return nil
}

// Load loads a vector store from disk
func (vs *VectorStore) Load(path string) error {
	file, err := os.Open(path)
	if err != nil {
		return fmt.Errorf("failed to open file: %w", err)
	}
	defer file.Close()

	vs.mu.Lock()
	defer vs.mu.Unlock()

	decoder := gob.NewDecoder(file)
	if err := decoder.Decode(&vs.entries); err != nil {
		return fmt.Errorf("failed to decode: %w", err)
	}

	return nil
}

// cosineSimilarity calculates cosine similarity between two vectors
func cosineSimilarity(a, b []float32) float32 {
	if len(a) != len(b) {
		return 0
	}

	var dotProduct, normA, normB float32
	for i := range a {
		dotProduct += a[i] * b[i]
		normA += a[i] * a[i]
		normB += b[i] * b[i]
	}

	if normA == 0 || normB == 0 {
		return 0
	}

	return dotProduct / (float32(math.Sqrt(float64(normA))) * float32(math.Sqrt(float64(normB))))
}
```

### 4. RAG Retriever (`internal/rag/retriever.go`)

```go
// Copyright Elasticsearch B.V.

package rag

import (
	"context"
	"fmt"
	"strings"
)

// Retriever retrieves relevant code chunks for a query
type Retriever struct {
	embedder    *OllamaEmbedder
	vectorStore *VectorStore
	topK        int
}

// NewRetriever creates a new retriever
func NewRetriever(embedder *OllamaEmbedder, vectorStore *VectorStore, topK int) *Retriever {
	if topK == 0 {
		topK = 10
	}
	return &Retriever{
		embedder:    embedder,
		vectorStore: vectorStore,
		topK:        topK,
	}
}

// Retrieve finds relevant code chunks for a CVE query
func (r *Retriever) Retrieve(ctx context.Context, cveID, description string, affectedPackages []string) ([]SearchResult, error) {
	// Build query combining CVE info and affected packages
	queryParts := []string{description}
	for _, pkg := range affectedPackages {
		queryParts = append(queryParts, pkg)
	}
	query := strings.Join(queryParts, " ")

	// Generate query embedding
	queryEmb, err := r.embedder.Embed(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("failed to embed query: %w", err)
	}

	// Search vector store
	results := r.vectorStore.Search(queryEmb, r.topK)

	// Filter by relevance (optional threshold)
	var filtered []SearchResult
	for _, r := range results {
		if r.Score > 0.3 { // Minimum similarity threshold
			filtered = append(filtered, r)
		}
	}

	return filtered, nil
}

// RetrieveByPackage finds code that imports specific packages
func (r *Retriever) RetrieveByPackage(ctx context.Context, packagePath string) ([]SearchResult, error) {
	// Generate embedding for the package path
	queryEmb, err := r.embedder.Embed(ctx, packagePath)
	if err != nil {
		return nil, fmt.Errorf("failed to embed package: %w", err)
	}

	// Search and filter by import
	results := r.vectorStore.Search(queryEmb, r.topK*2)

	var filtered []SearchResult
	for _, res := range results {
		// Check if chunk imports the package
		for _, imp := range res.Chunk.Imports {
			if strings.Contains(imp, packagePath) {
				filtered = append(filtered, res)
				break
			}
		}
	}

	return filtered, nil
}
```

### 5. RAG-Enhanced Ollama Analyzer (`internal/llm/ollama_rag.go`)

```go
// Copyright Elasticsearch B.V.

package llm

import (
	"context"
	"fmt"
	"strings"

	"github.com/elastic/cloud-on-k8s/v3/hack/cve-triage/internal/deps"
	"github.com/elastic/cloud-on-k8s/v3/hack/cve-triage/internal/parser"
	"github.com/elastic/cloud-on-k8s/v3/hack/cve-triage/internal/rag"
	"github.com/elastic/cloud-on-k8s/v3/hack/cve-triage/internal/vulncheck"
)

// OllamaRAGAnalyzer combines Ollama LLM with RAG for enhanced analysis
type OllamaRAGAnalyzer struct {
	ollama    *OllamaAnalyzer
	retriever *rag.Retriever
}

// Ensure OllamaRAGAnalyzer implements Provider interface
var _ Provider = (*OllamaRAGAnalyzer)(nil)

// NewOllamaRAGAnalyzer creates a RAG-enhanced Ollama analyzer
func NewOllamaRAGAnalyzer(ollamaURL, model string, retriever *rag.Retriever) *OllamaRAGAnalyzer {
	return &OllamaRAGAnalyzer{
		ollama:    NewOllamaAnalyzer(ollamaURL, model),
		retriever: retriever,
	}
}

// Name returns the provider name
func (o *OllamaRAGAnalyzer) Name() string {
	return fmt.Sprintf("Ollama RAG (%s)", o.ollama.model)
}

// IsAvailable checks if the analyzer is ready
func (o *OllamaRAGAnalyzer) IsAvailable(ctx context.Context) bool {
	return o.ollama.IsAvailable(ctx)
}

// Close releases resources
func (o *OllamaRAGAnalyzer) Close() error {
	return o.ollama.Close()
}

// Analyze performs RAG-enhanced CVE analysis
func (o *OllamaRAGAnalyzer) Analyze(
	ctx context.Context,
	cveInfo *parser.CVEInfo,
	depResult *deps.CheckResult,
	vulnResult *vulncheck.Result,
) (*AnalysisResult, error) {
	// Retrieve relevant code chunks
	codeContext, err := o.retrieveContext(ctx, cveInfo, depResult)
	if err != nil {
		// Fall back to non-RAG analysis if retrieval fails
		return o.ollama.Analyze(ctx, cveInfo, depResult, vulnResult)
	}

	// Build enhanced prompt with code context
	prompt := o.buildRAGPrompt(cveInfo, depResult, vulnResult, codeContext)

	// Generate analysis using Ollama
	return o.ollama.analyzeWithPrompt(ctx, prompt)
}

// retrieveContext retrieves relevant code chunks for the CVE
func (o *OllamaRAGAnalyzer) retrieveContext(
	ctx context.Context,
	cveInfo *parser.CVEInfo,
	depResult *deps.CheckResult,
) ([]rag.SearchResult, error) {
	if o.retriever == nil {
		return nil, fmt.Errorf("retriever not configured")
	}

	// Retrieve based on CVE description and affected packages
	return o.retriever.Retrieve(ctx, cveInfo.ID, cveInfo.Description, cveInfo.AffectedPackages)
}

// buildRAGPrompt creates a prompt with retrieved code context
func (o *OllamaRAGAnalyzer) buildRAGPrompt(
	cveInfo *parser.CVEInfo,
	depResult *deps.CheckResult,
	vulnResult *vulncheck.Result,
	codeContext []rag.SearchResult,
) string {
	var sb strings.Builder

	sb.WriteString(`You are a security analyst specializing in Kubernetes operators and Go applications.
Analyze the following CVE and determine its impact on ECK (Elastic Cloud on Kubernetes).

ECK is a Kubernetes operator that manages Elasticsearch, Kibana, APM Server, Enterprise Search,
Beats, Elastic Agent, Elastic Maps Server, and Logstash deployments on Kubernetes.

`)

	// Add retrieved code context
	if len(codeContext) > 0 {
		sb.WriteString("## Relevant ECK Code\n\n")
		sb.WriteString("The following code sections from ECK may be relevant to this CVE:\n\n")

		for i, result := range codeContext {
			if i >= 5 { // Limit to top 5 chunks
				break
			}
			sb.WriteString(fmt.Sprintf("### %s (%s:%d-%d)\n", 
				result.Chunk.Name, 
				result.Chunk.FilePath, 
				result.Chunk.StartLine, 
				result.Chunk.EndLine))
			sb.WriteString(fmt.Sprintf("Package: %s, Type: %s\n", 
				result.Chunk.Package, 
				result.Chunk.Type))
			sb.WriteString("```go\n")
			sb.WriteString(result.Chunk.Content)
			sb.WriteString("\n```\n\n")
		}
	}

	// Add CVE info (same as regular prompt)
	sb.WriteString("## CVE Information\n\n")
	sb.WriteString(fmt.Sprintf("**CVE ID**: %s\n", cveInfo.ID))
	sb.WriteString(fmt.Sprintf("**Severity**: %s (CVSS: %.1f)\n", cveInfo.Severity, cveInfo.CVSSScore))
	sb.WriteString(fmt.Sprintf("**Description**: %s\n\n", cveInfo.Description))

	// Add dependency and vulncheck results (abbreviated)
	sb.WriteString("## Analysis Data\n\n")
	if depResult.CVEAffectsECK {
		sb.WriteString("- Dependency matching: MATCH FOUND\n")
	} else {
		sb.WriteString("- Dependency matching: No match\n")
	}

	if vulnResult != nil && len(vulnResult.CVEMatches) > 0 {
		sb.WriteString("- govulncheck: VULNERABLE CODE PATHS FOUND\n")
		for _, v := range vulnResult.CVEMatches {
			if len(v.CalledBy) > 0 {
				sb.WriteString(fmt.Sprintf("  - %s: %s\n", v.ID, strings.Join(v.CalledBy, " ‚Üí ")))
			}
		}
	} else if vulnResult != nil {
		sb.WriteString("- govulncheck: No vulnerable paths found\n")
	}

	sb.WriteString(`
## Your Task

Based on the CVE information, the ECK code shown above, and the analysis data, provide:

1. **RISK_LEVEL**: HIGH, MEDIUM, LOW, or NONE
2. **SUMMARY**: 2-3 sentence summary with specific code references
3. **DETAILED_ANALYSIS**: Explain how ECK's code relates to the vulnerability
4. **AFFECTED_AREAS**: List specific ECK files/functions affected
5. **RECOMMENDATION**: What action to take
6. **CONFIDENCE**: HIGH, MEDIUM, or LOW

Format your response with these exact headers.
`)

	return sb.String()
}
```

### 6. Index Building Command

```go
// cmd/index/main.go
package main

import (
	"context"
	"fmt"
	"os"
	"time"

	"github.com/elastic/cloud-on-k8s/v3/hack/cve-triage/internal/rag"
)

func main() {
	if len(os.Args) < 2 {
		fmt.Println("Usage: index <repo-path> [output-path]")
		os.Exit(1)
	}

	repoPath := os.Args[1]
	outputPath := "data/vectors.gob"
	if len(os.Args) > 2 {
		outputPath = os.Args[2]
	}

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
	defer cancel()

	fmt.Println("üîç Building RAG index for ECK codebase...")
	fmt.Printf("   Repository: %s\n", repoPath)
	fmt.Printf("   Output: %s\n\n", outputPath)

	// Create embedder
	embedder := rag.NewOllamaEmbedder("", "")
	if !embedder.IsAvailable(ctx) {
		fmt.Println("‚ùå Ollama is not running. Start with: ollama serve")
		os.Exit(1)
	}
	model, dim := embedder.ModelInfo()
	fmt.Printf("üìä Embedding model: %s (dim=%d)\n\n", model, dim)

	// Chunk the repository
	fmt.Println("üìÅ Chunking source files...")
	chunker := rag.NewChunker(repoPath, 2000)
	chunks, err := chunker.ChunkRepository()
	if err != nil {
		fmt.Printf("‚ùå Failed to chunk repository: %v\n", err)
		os.Exit(1)
	}
	fmt.Printf("   Found %d code chunks\n\n", len(chunks))

	// Generate embeddings
	fmt.Println("üßÆ Generating embeddings (this may take a while)...")
	vectorStore := rag.NewVectorStore()
	
	batchSize := 10
	for i := 0; i < len(chunks); i += batchSize {
		end := i + batchSize
		if end > len(chunks) {
			end = len(chunks)
		}
		batch := chunks[i:end]

		for _, chunk := range batch {
			emb, err := embedder.Embed(ctx, chunk.Content)
			if err != nil {
				fmt.Printf("   ‚ö†Ô∏è  Failed to embed %s: %v\n", chunk.ID, err)
				continue
			}
			vectorStore.Add(chunk, emb)
		}

		fmt.Printf("   Progress: %d/%d chunks\n", end, len(chunks))
	}

	// Save vector store
	fmt.Printf("\nüíæ Saving vector store to %s...\n", outputPath)
	if err := os.MkdirAll("data", 0755); err != nil {
		fmt.Printf("‚ùå Failed to create data directory: %v\n", err)
		os.Exit(1)
	}
	if err := vectorStore.Save(outputPath); err != nil {
		fmt.Printf("‚ùå Failed to save: %v\n", err)
		os.Exit(1)
	}

	fmt.Printf("\n‚úÖ Index built successfully! %d vectors saved.\n", vectorStore.Size())
}
```

## CLI Usage

### Build Index (One-Time)

```bash
# Make sure Ollama is running with embedding model
ollama serve &
ollama pull nomic-embed-text

# Build index
cd hack/cve-triage
go run cmd/index/main.go ../.. data/vectors.gob
```

### Run Triage with RAG

```bash
# Pull LLM model if not already done
ollama pull llama3.2

# Run with RAG
./cve-triage \
  --llm=ollama-rag \
  --dry-run \
  --go-mod="../../go.mod" \
  --repo-path="../.." \
  --rag-index="data/vectors.gob" \
  --issue-body="CVE-2025-61727 affects crypto/x509..."
```

## Updated main.go Flags

```go
var (
	// ... existing flags ...
	
	// RAG flags
	useRAG       bool
	ragIndexPath string
)

func init() {
	// ... existing flags ...
	
	// RAG flags
	rootCmd.Flags().BoolVar(&useRAG, "use-rag", false, "Enable RAG for enhanced analysis")
	rootCmd.Flags().StringVar(&ragIndexPath, "rag-index", "data/vectors.gob", "Path to RAG vector index")
}
```

## Performance Estimates

| Operation | Time | Notes |
|-----------|------|-------|
| **Index building** | ~10-15 min | One-time, ~1000 chunks |
| **Embedding query** | ~100ms | Per query |
| **Vector search** | <10ms | In-memory |
| **LLM generation** | ~10-30s | Depends on model |

## Disk Space

| Component | Size |
|-----------|------|
| nomic-embed-text | 274 MB |
| llama3.2 | 2 GB |
| Vector index | ~50-100 MB |
| **Total** | ~2.5 GB |

## Comparison with Other RAG Options

| Aspect | Ollama RAG | Gemini RAG | Vertex AI | CodeBERT |
|--------|------------|------------|-----------|----------|
| **Cost** | **$0** ‚úÖ | ~$5/mo | ~$10/mo | ~$5/mo |
| **Rate limits** | **None** ‚úÖ | Yes | Higher | Yes |
| **Privacy** | **100%** ‚úÖ | Cloud | Cloud | Cloud |
| **Offline** | **Yes** ‚úÖ | No | No | No |
| **Setup effort** | Medium | Easy | Easy | Medium |
| **Quality** | Good | Better | Best | Good |
| **Speed** | Good | Fast | Fast | Medium |

## Summary

**Ollama RAG is ideal when:**
- You want zero API costs
- You need to run without rate limits
- Privacy is important (code stays local)
- You have ~3GB disk space for models
- You can wait for initial index build

**Trade-offs:**
- Slightly lower quality than cloud models
- Requires local compute resources
- Initial index building takes time

## Files to Create

| File | Purpose |
|------|---------|
| `internal/rag/embeddings.go` | Ollama embedding client |
| `internal/rag/chunker.go` | AST-aware Go code chunker |
| `internal/rag/vectorstore.go` | Local vector store with persistence |
| `internal/rag/retriever.go` | Similarity search |
| `internal/llm/ollama_rag.go` | RAG-enhanced Ollama analyzer |
| `cmd/index/main.go` | Index building command |

## Next Steps

1. Install Ollama and pull models
2. Implement the RAG components
3. Build the vector index for ECK
4. Add `--use-rag` flag to main.go
5. Test with sample CVEs

