// Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
// or more contributor license agreements. Licensed under the Elastic License 2.0;
// you may not use this file except in compliance with the Elastic License 2.0.

package rag

import (
	"fmt"
	"go/ast"
	"go/parser"
	"go/token"
	"io/fs"
	"os"
	"path/filepath"
	"strings"
)

// Chunker splits Go source files into semantic chunks
type Chunker struct {
	maxChunkSize int
	repoPath     string
}

// NewChunker creates a new code chunker
func NewChunker(repoPath string, maxChunkSize int) *Chunker {
	if maxChunkSize == 0 {
		maxChunkSize = 2000 // ~500 tokens
	}
	// Convert to absolute path to avoid issues with relative paths
	absPath, err := filepath.Abs(repoPath)
	if err == nil {
		repoPath = absPath
	}
	return &Chunker{
		maxChunkSize: maxChunkSize,
		repoPath:     repoPath,
	}
}

// ChunkRepository processes all Go files in the repository
func (c *Chunker) ChunkRepository() ([]CodeChunk, error) {
	var chunks []CodeChunk

	err := filepath.WalkDir(c.repoPath, func(path string, d fs.DirEntry, err error) error {
		if err != nil {
			return err
		}

		// Skip directories
		if d.IsDir() {
			name := d.Name()
			// Skip vendor, test, generated, and hidden directories
			if name == "vendor" || name == ".git" || name == "hack" || strings.HasPrefix(name, ".") {
				return filepath.SkipDir
			}
			return nil
		}

		// Only process .go files, skip tests
		if !strings.HasSuffix(path, ".go") || strings.HasSuffix(path, "_test.go") {
			return nil
		}

		// Skip generated files
		if strings.Contains(path, "zz_generated") {
			return nil
		}

		fileChunks, err := c.chunkFile(path)
		if err != nil {
			// Log error but continue with other files
			fmt.Printf("Warning: failed to chunk %s: %v\n", path, err)
			return nil
		}

		chunks = append(chunks, fileChunks...)
		return nil
	})

	return chunks, err
}

// chunkFile processes a single Go file into chunks
func (c *Chunker) chunkFile(filePath string) ([]CodeChunk, error) {
	fset := token.NewFileSet()
	node, err := parser.ParseFile(fset, filePath, nil, parser.ParseComments)
	if err != nil {
		return nil, err
	}

	content, err := os.ReadFile(filePath)
	if err != nil {
		return nil, err
	}

	var chunks []CodeChunk
	relPath, _ := filepath.Rel(c.repoPath, filePath)

	// Extract imports
	var imports []string
	for _, imp := range node.Imports {
		imports = append(imports, strings.Trim(imp.Path.Value, `"`))
	}

	// Process declarations
	for _, decl := range node.Decls {
		switch d := decl.(type) {
		case *ast.FuncDecl:
			chunk := c.extractFuncChunk(fset, d, relPath, node.Name.Name, imports, content)
			if chunk != nil {
				chunks = append(chunks, *chunk)
			}
		case *ast.GenDecl:
			chunkList := c.extractGenDeclChunks(fset, d, relPath, node.Name.Name, imports, content)
			chunks = append(chunks, chunkList...)
		}
	}

	return chunks, nil
}

// extractFuncChunk extracts a function/method as a chunk
func (c *Chunker) extractFuncChunk(fset *token.FileSet, fn *ast.FuncDecl, filePath, pkgName string, imports []string, content []byte) *CodeChunk {
	startPos := fset.Position(fn.Pos())
	endPos := fset.Position(fn.End())

	// Calculate byte positions
	startByte := int(fn.Pos()) - 1
	endByte := int(fn.End()) - 1
	if startByte < 0 || endByte > len(content) {
		return nil
	}

	code := string(content[startByte:endByte])
	if len(code) > c.maxChunkSize {
		// Truncate but keep signature
		code = code[:c.maxChunkSize] + "\n// ... truncated"
	}

	chunkType := "function"
	name := fn.Name.Name
	if fn.Recv != nil {
		chunkType = "method"
		// Get receiver type
		if len(fn.Recv.List) > 0 {
			if star, ok := fn.Recv.List[0].Type.(*ast.StarExpr); ok {
				if ident, ok := star.X.(*ast.Ident); ok {
					name = ident.Name + "." + name
				}
			} else if ident, ok := fn.Recv.List[0].Type.(*ast.Ident); ok {
				name = ident.Name + "." + name
			}
		}
	}

	return &CodeChunk{
		ID:        filePath + ":" + name,
		FilePath:  filePath,
		StartLine: startPos.Line,
		EndLine:   endPos.Line,
		Type:      chunkType,
		Name:      name,
		Package:   pkgName,
		Content:   code,
		Imports:   imports,
	}
}

// extractGenDeclChunks extracts type/const/var declarations
func (c *Chunker) extractGenDeclChunks(fset *token.FileSet, gen *ast.GenDecl, filePath, pkgName string, imports []string, content []byte) []CodeChunk {
	var chunks []CodeChunk

	for _, spec := range gen.Specs {
		switch s := spec.(type) {
		case *ast.TypeSpec:
			startPos := fset.Position(s.Pos())
			endPos := fset.Position(s.End())

			startByte := int(s.Pos()) - 1
			endByte := int(s.End()) - 1
			if startByte < 0 || endByte > len(content) {
				continue
			}

			code := string(content[startByte:endByte])
			if len(code) > c.maxChunkSize {
				code = code[:c.maxChunkSize] + "\n// ... truncated"
			}

			chunks = append(chunks, CodeChunk{
				ID:        filePath + ":" + s.Name.Name,
				FilePath:  filePath,
				StartLine: startPos.Line,
				EndLine:   endPos.Line,
				Type:      "type",
				Name:      s.Name.Name,
				Package:   pkgName,
				Content:   code,
				Imports:   imports,
			})
		}
	}

	return chunks
}

